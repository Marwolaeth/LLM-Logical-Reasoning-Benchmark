# LLM-Logical-Reasoning-Benchmark
A benchmark project designed to evaluate the logical reasoning capabilities of Large Language Models (LLMs). It utilises a multi-choice Natural Language Inference (NLI) task, adapted from human-designed logic tests, to assess how well LLMs can identify logically entailed hypotheses.
